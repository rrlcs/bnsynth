\section{Background}

\noindent\textbf{Basic Fuzzy Logic:} Basic Fuzzy Logic (BL)  is a relaxation of first-order logic that operates on continuous truth
values on the interval [0, 1] instead of on boolean values. BL
uses a class of functions called \textit{t-norms} ($\otimes$), which preserves
the semantics of boolean conjunctions on continuous truth
values. Formally, a t-norm is defined $\otimes$ : $[0, 1] \times [0, 1] \rightarrow [0, 1]$ such that:
\begin{itemize}
    \item $\otimes$ is consistent for any $t \in [0, 1]:$ 

            \quad \quad \quad  $$t \otimes 1 = t \quad\quad t \otimes 0 = 0$$
    % \item \otimes \text{is commutative and associative for any t \in [0, 1]:} $$ t_{1} \otimes t_{2} = t_{2} \otimes t_{1} \quad t_{1} \otimes (t_{2} \otimes t_{3}) = (t_{1} \otimes t_{2}) \otimes t_{3} $$
\end{itemize}

\begin{itemize}
    \item $\otimes$ \text{is commutative and associative for any $t \in [0, 1]$:} 
    
        $$ t_{1} \otimes t_{2} = t_{2} \otimes t_{1} \quad t_{1} \otimes (t_{2} \otimes t_{3}) = (t_{1} \otimes t_{2}) \otimes t_{3} $$
\end{itemize}

\begin{itemize}
    \item $\otimes$ is monotonic (non decreasing) for any $t \in [0, 1]$:

        $$ t_{1} \leq t_{2} \implies t_{1} \otimes t_{3} \leq t_{2} \otimes t_{3} $$
\end{itemize}

\begin{table*}[t]
\begin{tabular*}{\textwidth}{c @{\extracolsep{\fill}} cccc}
  & Lukaseiwicz: & Godel: & Product: \\ 
 tnorm ($\otimes$) & $max(0, t + u − 1)$ & $min(t, u)$ & $t * u$ \\  
 tconorm ($\oplus$) & $min(t + u, 1)$ & $max(t, u)$ & $t + u - t * u$
\end{tabular*}
\caption{}
\label{tab:tnorm_conorm}
\end{table*}

\noindent BL additionally requires that t-norms be continuous. \textit{T-conorms} ($\oplus$) are derived from t-norms via DeMorgan’s law and operate as disjunctions on continuous truth values, while negations are defined $\neg{t} := 1 - t$.

\noindent Three widely used t-norms that satisfy the requirements are the
Lukaseiwicz t-norm \cite{luka}, the Godel t-norm \cite{baaz1996} and the product t-norm \cite{hajek1996}. Each t-norm has a \textit{t-conorm} associated with it (denoted $\oplus$), which can be
considered as logical disjunction. Given a t-norm $\otimes$, the t-conorm can be derived with DeMorgan’s
law: $t \oplus u$ $\overset{\Delta}{=}$ $\neg{(\neg{t} \otimes \neg{u})}$. Table \ref{tab:tnorm_conorm} shows the formule for tnorms and tconorms.

% \centering


\noindent\textbf{Gated t-norms and gated t-conorms:} Given a classic t-norm $T(x, y) = x \otimes y$, we define its associated gated t-norm as 

$$T_{G}(x,y;g_{1},g_{2}) = (1*(1 - g_{1}) + x*g_{1}) \otimes (1*(1 - g_{2}) + y*g_{2})$$

Here $g_{1}, g_{2} \in [0, 1]$ are gate parameters indicating if x and y are activated, respectively.

Gates $g_{1}, g_{2}$ are learnt from Neural Network.

\noindent Given a threshold T let,
\[
    g_{i}^{'} =
    \begin{cases}
        1 & g_{i} > T\\
        0 & otherwise
    \end{cases}    
\]

\[\label{def}
    T_{G}(x,y;g_{1}^{'},g_{2}^{'})= 
\begin{cases}
    x \otimes y & g_{1}^{'} = 1 \hspace{2mm} \text{and} \hspace{2mm} g_{2}^{'} = 1\\
    x & g_{1}^{'} = 1 \hspace{2mm} \text{and} \hspace{2mm} g_{2}^{'} = 0\\
    y & g_{1}^{'} = 0 \hspace{2mm} \text{and} \hspace{2mm} g_{2}^{'} = 1\\
    1 & g_{1}^{'} = 0 \hspace{2mm} \text{and} \hspace{2mm} g_{2}^{'} = 0
\end{cases}
\]

\noindent $(1 + g_{1}(x - 1))$ gives a convex combination of $1$ and $x$ for the values of $g_{1}$ and $g_{2}$ $\in (0, 1)$.
Similarly, for $(1 + g_{1}(y - 1))$

Using DeMorgan’s laws $x \otimes y = 1 - ((1 - x) \otimes (1 - y))$, we define gated t-conorms as

$$T_{G}^{'}(x,y;g_{1},g_{2}) = 1 - ((1 - g_{1}*x) \otimes (1 - g_{2}*y))$$,

and has following property - 
\[
    T_{G}^{'}(x,y;g_{1}^{'},g_{2}^{'})= 
\begin{cases}
    x \otimes y & g_{1}^{'} = 1 \hspace{2mm} \text{and} \hspace{2mm} g_{2}^{'} = 1\\
    x & g_{1}^{'} = 1 \hspace{2mm} \text{and} \hspace{2mm} g_{2}^{'} = 0\\
    y & g_{1}^{'} = 0 \hspace{2mm} \text{and} \hspace{2mm} g_{2}^{'} = 1\\
    0 & g_{1}^{'} = 0 \hspace{2mm} \text{and} \hspace{2mm} g_{2}^{'} = 0
\end{cases}
\]

\noindent\textbf{Continuous Logic Network (CLN):} CLN's are based on parametric relaxation Logical formulas that maps the logical formulation from boolean first order logic to BL.
The model defines the operator $\mathcal{S}$. A quantifier-free boolean formula $F: X \rightarrow {True, False}$, $\mathcal{S}$ maps it to a continuous function 
$\mathcal{S}(F): X \rightarrow [0, 1]$. In order for the continuous model to be both usable in gradient-guided optimization while also preserving the semantics of boolean
logic, it must fulfill three conditions:

\begin{enumerate}
    \item It must preserve the meaning of the logic, such that the continuous truth values of a valid assignment are always greater than the value of an invalid assignment:
        \begin{dmath*}$(F(x) = True \wedge F(x') = False) \implies \mathcal{S}(F)(x) > \mathcal{S}(F)(x')$\end{dmath*}
    \item It must be must be continuous and smooth (i.e. differentiable almost everywhere) to facilitate training.
    \item It must be strictly increasing as an unsatisfying assignment of terms approach satisfying the mapped formula,
and strictly decreasing as a satisfying assignment of
terms approach violating the formula.
\end{enumerate}

\script{S} is constructed as follows to satisfy these requirements. The
logical relations {$\wedge, \lor, \lnot$} are mapped to their continuous
equivalents in BL:

$$Conjunction: \script{S}(F_{1} \wedge F_{2}) \triangleq \script{S} (F_{1}) \otimes \mathcal{S} (F_{2})$$
$$Disjunction: \script{S}(F_{1} \lor \F_{2}) \triangleq \script{S} (F_{1}) \otimes \mathcal{S} (F_{2})$$
$$Negation: \script{S}(\neg{F}) \triangleq 1 - \script{S}(F)$$

For Gated CLN, we use gated t-norms and gated t-conorms.

\section{Theorems}
\noindent\textbf{Theorem 1: } For any Boolean Formula F, there exists a CLN model M, such that
\begin{equation}
    \forall x, 0 <= M(x) <= 1 \\
\end{equation}
\begin{equation}
    \forall, F(x) = True \iff M(x) = 1 \\
\end{equation}
\begin{equation}
    \forall, F(x) = False \iff M(x) = 0
\end{equation}

In Boolean Function Setting, formula F as defined as follows:
$$F:\rightarrow p | F_1 \lor F_2 | F_1 \wedge F_2$$
where p is either x or \neg x.

We prove this theorem by structural induction on F assuming the model vanilla CLN.

\noindent\paragraph{Atomic Case: } F is simply a proposition p. CLN constructed 
for the atomic case would consist of only one neuron which would give us back the inputs.

$\therefore$ By construction, $\forall x F(x) = True \iff M(x) = 1$

Since M(x) is identity and p is either 0 or 1, $0 \leq M(x) \geq 1$

\noindent\paragraph{Disjunction Case: } $F = F_1 \lor F_2$. 
Assume that $F_1$ and $F_2$ hold the induction hypothesis.

$\therefore$ $F_1$ can be represented by $M_1$ and $F_2$ can be represented by $M_2$

s.t. ($F_1$, $M_1$) and ($F_2$, $M_2$) satisfies equations 1, 2, and 3.

Now let $p_1$ and $p_2$ are the ouput nodes of $M_1$ and $M_2$. We add a final output node $p = p_1 \oplus p_2$.
So, $M(x) = M_1(x) \oplus M_2(x)$

since $\oplus$ is continuous and $M_1$, $M_2$ follows induction hypothesis,
M(x) is continuous as well.

$\therefore 0 \leq M(x) \geq 1$

\noindent\textbf{Forward Implication: } If F(x) is True then either $F_1(x)$ or $F_2(x)$
is true. Without loss of generality let's assume $F_1(x) = True$.

So, from induction hypothesis we know that $M_1(x) = 1$.

Using property of tconorm $t \oplus u \leq t^{'} \oplus u$ for $t \geq 0$ and $t \leq t^{'}$ 

Also, from induction hypothesis, $M_2(x)$ \geq 0

we get, $0 \oplus M_1(x) \leq M_2(x) \oplus M_1(x)$

$0 \oplus M_1(x) = M_1(x)$ [By definition of tconorm]

$\therefore M_1(x) \leq M(x) \leq 1$

and we know that M_1(x) = 1 by induction hypothesis
$$\therefore M(x) = 1$$

\noindent\textbf{Backward Implication: } We have M(x) = 1 \\
\iff M_1(x) \oplus M_2(x) = 1 \\
\iff 1 - (1 - p_1) \otimes (1 - p_2) = 1 \\
\iff (1 - p_1) \otimes (1 - p_2) = 0

from induction hypothesis, we know that either M_1 = 1 or M_2 = 1. Without loss of generality, 
let $M_1 = 1$ \\
$\iff p_1 = 1$ \\
$\iff F_1(x) = True$

as $F(x) = F_1(x) \lor F_2(x)$, we get
$F(x) = True$

Similarly, we can also prove for the Conjunction case.
