\section{Research Proposal}
In this section, we discuss our research idea in detail. We first discuss the overall idea of our research using a block diagram. We then discuss a neural network architecture that we propose for the problem. We also explain DeepSynth's NN architecture for clarity.. Finally, we conclude with a discussion on how to generate a dataset to train this problem. The benchmarks that we are looking into are the standard SyGuS benchmarks.


% -------------- CODE FOR GOAL ARCHITECTURE ------------------

\begin{figure*}
\resizebox{!}{!}{%
\begin{tikzpicture}[node distance=2cm]
\node (pr) [process] {LOGICAL SPEC};
\node (sam) [startstop, right of=pr, xshift=1.5cm] {SAMPLER};
\node (nn) [startstop, right of=sam, xshift=2cm] {PRE-TRAINED NN FOR SKETCHES FOR A GIVEN GRAMMAR};
\node (sol) [startstop, right of=nn, xshift=2.5cm] {SOLVER};
\node (bs) [process, below of=nn, yshift=-0.5cm] {BAD SKETCH};
\node (gr) [process, above of=sol, yshift=0.5cm] {GRAMMAR};
\node (dec1) [decision, below of=sol, yshift=-0.5cm] {SOLVED?};
\node (sn) [solution, below of=dec1, yshift=-0.5cm] {PROGRAM};
\draw [arrow] (pr) -- node[anchor=south] {} (sam);
\draw[-latex,bend right=45]  (pr) edge (nn);
\draw [arrow] (sam) -- node[anchor=south] {I/O} (nn);
\draw [arrow] (sam) -- node[anchor=north] {Examples} (nn);
\draw [arrow] (nn) -- node[anchor=south] {SKETCHES} (sol);
\draw [arrow] (sol) -- node[anchor=south] {} (dec1);
\draw [arrow] (gr) -- node[anchor=south] {} (sol);
\draw [arrow] (dec1) -- node[anchor=south] {NO} (bs);
\draw [arrow] (bs) -- node[anchor=south] {} (nn);
\draw [arrow] (dec1) -- node[anchor=west] {YES} (sn);
\end{tikzpicture}
}
\caption{Synthesizing Sketches from Logical Embeddings}
\label{fig:goal}
\end{figure*}



%\Stanly{See where this fits in........We propose how to synthesize the dataset from existing SyGuS benchmarks.
%We propose an architecture for an NN that takes an embedding of I/O + Logical Formula and synthesizes a sketch which is expected to work better than previous approaches. The reason is because we encode the semantics of the logical spec using GNN.
%As a consequence of the above two points, we will also have a baseline approach that synthesizes complete programs from logical spec embeddings.
%Lastly, we wish to think about teaching the NN to recognise "bad sketches" which is now feasible due to this architecture.}

\subsection{Overall idea}

Figure \ref{fig:goal} describes the high level idea for synthesizing sketches from logical embeddings. We first sample a finite set of I/O examples from the logical specification. We wish to have a pre trained neural network for a given DSL that is trained to generate the required sketches when a logical specification and I/O specification are given as input. As a novel extension, it may also be possible for the NN to take as input a bad sketch and make decisions accordingly. This would be something similar to CEGIS(T) but using an NN. We then feed it to a traditional solver that solves the sketch using enumerative techniques if the sketch has non constant holes and constraint based techniques, if the sketch has constant holes. If the sketch is infeasible, then we use this to direct our NN to synthesize a better sketch. The meaning of an infeasible sketch is that there does not exist a valid (w.r.t. the DSL) completion of the sketch for the given specification.

The major research question here is how to make the NN understand whether a given sketch is an infeasible sketch or not.